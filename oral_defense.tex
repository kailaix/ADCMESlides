%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beamer Presentation
% LaTeX Template
% Version 1.0 (10/11/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%    PACKAGES AND THEMES
%----------------------------------------------------------------------------------------

\documentclass[usenames,dvipsnames]{beamer}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{algorithm}

\usepackage{animate}
\usepackage{float}
\usepackage{bm}
\usepackage{mathtools}
\usepackage{extarrows}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{minted}

\newcommand{\uc}{\underline{c}}
\newcommand{\ChoL}{\mathsf{L}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\ii}{\mathrm{i}}
\newcommand{\bxi}{\bm{\xi}}
\newcommand{\bmu}{\bm{\mu}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\bA}{\mathbf{A}}
\newcommand{\bJ}{\mathbf{J}}
\newcommand{\bB}{\mathbf{B}}
\newcommand{\bM}{\mathbf{M}}

\newcommand{\by}{\mathbf{y}}
\newcommand{\bw}{\mathbf{w}}

\newcommand{\bX}{\mathbf{X}}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\bs}{\mathbf{s}}
\newcommand{\sign}{\mathrm{sign}}
\newcommand{\bt}[0]{\bm{\theta}}
\newcommand{\bc}{\mathbf{c}}
\newcommand{\bzero}{\mathbf{0}}
\renewcommand{\bf}{\mathbf{f}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bv}[0]{\mathbf{v}}

\mode<presentation> {

% The Beamer class comes with a number of default slide themes
% which change the colors and layouts of slides. Below this is a list
% of all the themes, uncomment each in turn to see what they look like.

%\usetheme{default}
%\usetheme{AnnArbor}
%\usetheme{Antibes}
%\usetheme{Bergen}
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Boadilla}
%\usetheme{CambridgeUS}
%\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{Dresden}
%\usetheme{Frankfurt}
%\usetheme{Goettingen}
%\usetheme{Hannover}
%\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
\usetheme{Madrid}
%\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
%\usetheme{PaloAlto}
%\usetheme{Pittsburgh}
%\usetheme{Rochester}
%\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Warsaw}


% As well as themes, the Beamer class has a number of color themes
% for any slide theme. Uncomment each of these in turn to see how it
% changes the colors of your current slide theme.

%\usecolortheme{albatross}
\usecolortheme{beaver}
%\usecolortheme{beetle}
%\usecolortheme{crane}
%\usecolortheme{dolphin}
%\usecolortheme{dove}
%\usecolortheme{fly}
%\usecolortheme{lily}
%\usecolortheme{orchid}
%\usecolortheme{rose}
%\usecolortheme{seagull}
%\usecolortheme{seahorse}
%\usecolortheme{whale}
%\usecolortheme{wolverine}

%\setbeamertemplate{footline} % To remove the footer line in all slides uncomment this line
%\setbeamertemplate{footline}[page number] % To replace the footer line in all slides with a simple slide count uncomment this line

%\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the bottom of all slides uncomment this line
}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage{soul}
\newcommand{\red}[1]{\textcolor{red}{#1}}
%
%\usepackage{graphicx} % Allows including images
%\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
%
%
%\usepackage{amsthm}
%
%\usepackage{todonotes}
%\usepackage{floatrow}
%
%\usepackage{pgfplots,algorithmic,algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
%\usepackage[toc,page]{appendix}
%\usepackage{float}
%\usepackage{booktabs}
%\usepackage{bm}
%
%\theoremstyle{definition}
%
\newcommand{\RR}[0]{\mathbb{R}}
%
%\newcommand{\bx}{\mathbf{x}}
%\newcommand{\ii}{\mathrm{i}}
%\newcommand{\bxi}{\bm{\xi}}
%\newcommand{\bmu}{\bm{\mu}}
%\newcommand{\bb}{\mathbf{b}}
%\newcommand{\bA}{\mathbf{A}}
%\newcommand{\bJ}{\mathbf{J}}
%\newcommand{\bB}{\mathbf{B}}
%\newcommand{\bM}{\mathbf{M}}
%\newcommand{\bF}{\mathbf{F}}
%
%\newcommand{\by}{\mathbf{y}}
%\newcommand{\bw}{\mathbf{w}}
%\newcommand{\bn}{\mathbf{n}}
%
%\newcommand{\bX}{\mathbf{X}}
%\newcommand{\bY}{\mathbf{Y}}
%\newcommand{\bs}{\mathbf{s}}
%\newcommand{\sign}{\mathrm{sign}}
%\newcommand{\bt}[0]{\bm{\theta}}
%\newcommand{\bc}{\mathbf{c}}
%\newcommand{\bzero}{\mathbf{0}}
%\renewcommand{\bf}{\mathbf{f}}
%\newcommand{\bu}{\mathbf{u}}
%\newcommand{\bv}[0]{\mathbf{v}}

\AtBeginSection[]
{
   \begin{frame}
       \frametitle{Outline}
       \tableofcontents[currentsection]
   \end{frame}
}

%----------------------------------------------------------------------------------------
%    TITLE PAGE
%----------------------------------------------------------------------------------------
\usepackage{bm}
\newcommand*{\TakeFourierOrnament}[1]{{%
\fontencoding{U}\fontfamily{futs}\selectfont\char#1}}
\newcommand*{\danger}{\TakeFourierOrnament{66}}

\title[Kailai Xu]{Machine Learning for Inverse Problems in Computational Engineering} % The short title appears at the bottom of every slide, the full title is only on the title page

\author[Kailai Xu]{Kailai Xu \\ Stanford University} % Your name


\setbeamertemplate{footline}{
	\hbox{%
		\begin{beamercolorbox}[wd=\paperwidth,ht=3ex,dp=1.5ex,leftskip=2ex,rightskip=2ex]{page footer}%
			\usebeamerfont{title in head/foot}%
			\insertshorttitle \hfill
			\insertsection \hfill
			\insertframenumber{} / \inserttotalframenumber
	\end{beamercolorbox}}%
}
%\institute[] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
%{
%%ICME, Stanford University \\ % Your institution for the title page
%%\medskip
%%\textit{kailaix@stanford.edu}\quad \textit{darve@stanford.edu} % Your email address
%}
\date{}% Date, can be changed to a custom date
% Mathematics of PDEs

	\usepackage{cleveref}
\begin{document}


\usebackgroundtemplate{%
\begin{picture}(0,250)
\centering
	{{\includegraphics[width=1.0\paperwidth]{figures/background}}}
\end{picture}
  } 
%\usebackgroundtemplate{%
%  \includegraphics[width=\paperwidth,height=\paperheight]{figures/back}} 
\begin{frame}

\titlepage % Print the title page as the first slide

%dfa
\end{frame}
\usebackgroundtemplate{}

\section{Inverse Modeling}



\begin{frame}
	\frametitle{Inverse Modeling}
	\begin{figure}
		\centering
		\includegraphics[width=1.0\textwidth]{figures/inverse3}
	\end{figure}
\end{frame}



\begin{frame}
	\frametitle{Inverse Modeling}
	We can formulate inverse modeling as a PDE-constrained optimization problem 
	\begin{equation*}
		\min_{\theta} L_h(u_h) \quad \mathrm{s.t.}\; F_h(\theta, u_h) = 0
	\end{equation*}
	\begin{itemize}
		\item The \textcolor{red}{loss function} $L_h$ measures the discrepancy between the prediction $u_h$ and the observation $u_{\mathrm{obs}}$, e.g., $L_h(u_h) = \|u_h - u_{\mathrm{obs}}\|_2^2$. 
		\item $\theta$ is the \textcolor{red}{model parameter} to be calibrated. 
		\item The \textcolor{red}{physics constraints} $F_h(\theta, u_h)=0$ are described by a system of partial differential equations or differential algebraic equations (DAEs); e.g., 
		$$F_h(\theta, u_h) = \mathbf{A}(\theta) u_h - f_h = 0$$
	\end{itemize}
\end{frame}




\begin{frame}
	\frametitle{Function Inverse Problem}
	
	\begin{equation*}
		\min_{\textcolor{red}{f}} L_h(u_h) \quad \mathrm{s.t.}\; F_h(\textcolor{red}{f}, u_h) = 0
	\end{equation*}
	
	What if the unknown is a \textcolor{red}{function} instead of a set of parameters?
\begin{itemize}
	\item Koopman operator in dynamical systems.
	\item Constitutive relations in solid mechanics. 
	\item Turbulent closure relations in fluid mechanics.
	\item ...
\end{itemize}

The candidate solution space is \textcolor{red}{infinite dimensional}.

\end{frame}


\begin{frame}
	\frametitle{Penalty Methods}
	
	\begin{itemize}
		\item Parametrize $f$ with $f_\theta$ and incorporate the physical constraint as a \textcolor{red}{penalty term} (regularization, prior, \ldots) in the loss function.
		\begin{equation*}
	\min_{\theta,\,u_h} L_h(u_h) + \lambda\|F_h(f_\theta, u_h)\|_2^2
		\end{equation*}
		\begin{itemize}
			\item May not satisfy physical constraint $F_h(f_\theta, u_h)=0$ accurately;
			\item Slow convergence for \textcolor{red}{stiff} problems;
			\begin{figure}[hbt]
				\includegraphics[width=0.6\textwidth]{figures/slowconvergence.png}
			\end{figure}
			
			
			\item High dimensional optimization problem; both $\theta$ and $u_h$ are variables.
		\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}
	\frametitle{Machine Learning for Computational Engineering}
	$$\min_{\theta} L_h(u_h) \quad \mathrm{s.t.}\;\boxed{F_h(\textcolor{red}{NN_\theta}, u_h) = 0} \leftarrow \mbox{Solved numerically}$$
	\vspace{-0.5cm}
	\begin{enumerate}
		\item Use a deep neural network to approximate the (high dimensional) unknown function;
		\item Solve $u_h$ from the physical constraint using a numerical PDE solver;
		\item Apply an unconstrained optimizer to the reduced problem
		$$\min_{\theta} L_h(\textcolor{red}{u_h(\theta)})$$
	\end{enumerate}
	\vspace{-0.3cm}
	\begin{figure}[hbt]
		\includegraphics[width=0.75\textwidth]{figures/physics_based_machine_learning.png}
	\end{figure}
\end{frame}



\begin{frame}
	\frametitle{Gradient Based Optimization}
		$$\min_{\theta} L_h({u_h(\theta)})$$
	
	\begin{itemize}
		\item Steepest descent method:
		$$\theta_{k+1} \gets \theta_k - \alpha_k \nabla_\theta L_h(u_h(\theta_k))$$ 
	\end{itemize}
	
	\begin{figure}[hbt]
	\centering
  \includegraphics[width=0.6\textwidth]{figures/im.pdf}
\end{figure}

\end{frame}


\begin{frame}{Research Question}
	
	\textbf{Overall}
	
	\vspace{0.2cm}
	
	\begin{quote}
	Develop algorithms and tools for solving inverse problems by \\ combining DNNs and numerical PDE solvers. 
	\end{quote}

	
	
	Specifically, I discuss my contributions on:	
\begin{enumerate}
\item how to reconcile gradient calculations in both numerical PDE solvers and deep neural networks using \textcolor{red}{automatic differentiation};
\item how to calculate gradients for \textcolor{red}{implicit and/or iterative operators} in sophisticated numerical solvers;
\item how to \textcolor{red}{accelerate convergence and improve accuracy} with \textcolor{red}{Hessian information};
\item how to solve \textcolor{red}{stochastic} inverse problems. 
\end{enumerate}
\end{frame}



\section{Automatic Differentiation}

\begin{frame}{Motivation}

\textbf{Question}

\

\begin{quote}
	How deep neural networks communicate gradients with numerical PDE solvers?
\end{quote}

\end{frame}

\begin{frame}
	\frametitle{Automatic Differentiation}
	The fact that bridges the \textcolor{red}{technical} gap between machine learning and inverse modeling:
	\begin{itemize}
		\item Deep learning (and many other machine learning techniques) and numerical schemes share the same computational model: composition of individual operators. 
	\end{itemize}
	
	
	\begin{minipage}[t]{0.4\textwidth}
		
		\
		
		
		
		\begin{center}
			\textcolor{red}{Mathematical Fact}
			
			\
			
			Back-propagation 
			
			$||$
			
			Reverse-mode
			
			Automatic Differentiation 
			
			$||$
			
			Discrete 
			
			Adjoint-State Method
		\end{center}
	\end{minipage}~
	\begin{minipage}[t]{0.6\textwidth}
		\begin{figure}[hbt]
			\includegraphics[width=0.8\textwidth]{figures/compare-NN-PDE.png}
		\end{figure}
	\end{minipage}
	
\end{frame}

\begin{frame}
	\frametitle{Computational Graph for Numerical Schemes}
	
	\begin{itemize}
		\item To leverage automatic differentiation for inverse modeling, we need to express the numerical schemes in the ``AD language'': computational graph. 
		\item No matter how complicated a numerical scheme is, it can be decomposed into a collection of operators that are interlinked via state variable dependencies. 
	\end{itemize}
	
	\begin{figure}[hbt]
		\includegraphics[width=1.0\textwidth]{figures/cgnum}
	\end{figure}
	
	
	
\end{frame}


\begin{frame}
	\frametitle{ADCME: Computational-Graph-based Numerical Simulation}
	
	\begin{figure}[hbt]
		\includegraphics[width=1.0\textwidth]{figures/custom}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{How ADCME works}
	\begin{itemize}
		\item ADCME translates your numerical simulation codes to computational graph and then the computations are delegated to a heterogeneous task-based parallel computing environment through TensorFlow runtime. 
	\end{itemize}
	\begin{figure}[hbt]
		\includegraphics[width=1.0\textwidth]{figures/routine2.png}
	\end{figure}
\end{frame}

\begin{frame}{Summary}

\begin{itemize}
\item Mathematically equivalent techniques for calculating gradients:

\begin{itemize}
\item gradient back-propagation (DNN)
\item discrete adjoint-state methods (PDE)
\item reverse-mode automatic differentiation
\end{itemize}

\item Computational graphs bridge the gap between gradient calculations in numerical PDE solvers and DNNs. 

\item ADCME extends the capability of TensorFlow to PDE solvers, providing users a single piece of software for numerical simulations, deep learning, and optimization.


\end{itemize}

\end{frame}

\section{First Order Physics Constrained Learning}

\begin{frame}
	
	
	\frametitle{Motivation}
	
	
	\begin{minipage}{0.695\textwidth}
		\vspace{-6cm}
		\begin{itemize}
			\item Most AD frameworks only deal with \textcolor{red}{explicit operators}, i.e., the functions that has analytical derivatives, or composition of these functions. 
			\item Many scientific computing algorithms are \textcolor{red}{iterative} or \textcolor{red}{implicit} in nature.
			\vspace{1cm}
			{\small
			\begin{table}[]
				\begin{tabular}{@{}lll@{}}
					\toprule
					Linear/Nonlinear & Explicit/Implicit & Expression   \\ \midrule
					Linear           & Explicit          & $y=Ax$       \\
					Nonlinear        & Explicit          & $y = F(x)$   \\
					\textbf{Linear}           & \textbf{Implicit}          & $Ay = x$     \\
					\textbf{Nonlinear}        & \textbf{Implicit}          & $F(x,y) = 0$ \\ \bottomrule
				\end{tabular}
			\end{table}
		}
		\end{itemize}
	\end{minipage}~
	\begin{minipage}[t]{0.3\textwidth}
		\includegraphics[width=1.0\textwidth]{figures/implicitvsexplicit.png}
	\end{minipage}
	
	% Please add the following required packages to your document preamble:
	% \usepackage{booktabs}
	
\end{frame}

\begin{frame}
	\frametitle{Example}
	
	\begin{itemize}
		\item Consider a function $f:x\rightarrow y$, which is implicitly defined by 
		$$F(x,y) = x^3 - (y^3+y) = 0$$
		If not using the cubic formula for finding the roots, the forward computation consists of iterative algorithms, such as the Newton's method and bisection method
	\end{itemize}
	
	
	
	\begin{minipage}[t]{0.48\textwidth}
		\centering
		\begin{algorithmic}
			\State $y^0 \gets 0$
			\State $k \gets 0$
			\While {$|F(x, y^k)|>\epsilon$}
			\State $\delta^k \gets F(x, y^k)/F'_y(x,y^k)$
			\State $y^{k+1}\gets y^k - \delta^k$
			\State $k \gets k+1$
			\EndWhile
			\State \textbf{Return} $y^k$
		\end{algorithmic}
	\end{minipage}~
	\begin{minipage}[t]{0.48\textwidth}
		\centering
		\begin{algorithmic}
			\State $l \gets -M$, $r\gets M$, $m\gets 0$
			\While {$|F(x, m)|>\epsilon$}
			\State $c \gets \frac{a+b}{2}$
			\If{$F(x, m)>0$}
			\State $a\gets m$
			\Else
			\State $b\gets m$
			\EndIf
			\EndWhile
			\State \textbf{Return} $c$
		\end{algorithmic}
		
	\end{minipage}	
	
\end{frame}

\begin{frame}
	\frametitle{Example}
	
	\begin{itemize}
		%		\item A simple approach is to save part or all intermediate steps, and ``back-propagate''. This approach is expensive in both computation and memory\footnote{Ablin, Pierre, Gabriel Peyr�, and Thomas Moreau. ``Super-efficiency of automatic differentiation for functions defined as a minimum.''}.
		%		\item Nevertheless, the simple approach works in some scenarios where accuracy or cost is not an issue, e.g., automatic differetiation of soft-DTW and Sinkhorn distance. 
		\item An efficient way to do automatic differentiation is to apply the \textcolor{red}{implicit function theorem}. For our example, $F(x,y)=x^3-(y^3+y)=0$; treat $y$ as a function of $x$ and take the derivative on both sides
		$$3x^2 - 3y(x)^2y'(x)-y'(x)=0\Rightarrow y'(x) = \frac{3x^2}{3y^2+1}$$
		The above gradient is \textcolor{red}{exact}.
	\end{itemize}
	\begin{center}
		\textbf{Can we apply the same idea to inverse modeling?}
	\end{center}
	
\end{frame}



\begin{frame}
	\frametitle{Physics Constrained Learning (PCL)}
	$${\small    \min_{\theta}\; L_h(u_h) \quad \mathrm{s.t.}\;\; F_h(\theta, u_h) = 0}$$
	\begin{itemize}
		\item Assume that we solve for $u_h=G_h(\theta)$ with $F_h(\theta, u_h)=0$, and then
		$${\small\tilde L_h(\theta)  = L_h(G_h(\theta))}$$
		\item Applying the \textcolor{red}{implicit function theorem}
		{  \scriptsize
			\begin{equation*}
				\frac{{\partial {F_h(\theta, u_h)}}}{{\partial \theta }} + {\frac{{\partial {F_h(\theta, u_h)}}}{{\partial {u_h}}}}
				\textcolor{red}{\frac{\partial G_h(\theta)}{\partial \theta}}
				= 0 \Rightarrow
				\textcolor{red}{\frac{\partial G_h(\theta)}{\partial \theta}} =  -\Big( \frac{{\partial {F_h(\theta, u_h)}}}{{\partial {u_h}}} \Big)^{ - 1} \frac{{\partial {F_h(\theta, u_h)}}}{{\partial \theta }}
			\end{equation*}
		}
		\item Finally we have
		{\scriptsize
			\begin{equation*}
				\boxed{\frac{{\partial {{\tilde L}_h}(\theta )}}{{\partial \theta }}
					= \frac{\partial {{ L}_h}(u_h )}{\partial u_h}\frac{\partial G_h(\theta)}{\partial \theta}=
					- \textcolor{red}{ \frac{{\partial {L_h}({u_h})}}{{\partial {u_h}}} } \;
					\textcolor{blue}{ \Big( {\frac{{\partial {F_h(\theta, u_h)}}}{{\partial {u_h}}}\Big|_{u_h = {G_h}(\theta )}} \Big)^{ - 1} } \;
					\textcolor{ForestGreen}{ \frac{{\partial {F_h(\theta, u_h)}}}{{\partial \theta }}\Big|_{u_h = {G_h}(\theta )} }
				}
			\end{equation*}
		}
		
	\end{itemize}
	
\end{frame}





\begin{frame}
	\frametitle{Physics Constrained Learning for Stiff Problems}
	
	\begin{itemize}
		\item For stiff problems, better to resolve physics using PCL.
		\item Consider a model problem 
		\begin{gather*}
			\min_{\theta} \|u-u_0\|^2_2 \qquad \text{s.t.} \;\; Au = \theta y
		\end{gather*}
	\vspace{-0.5cm}
	\begin{align*}
		\text{PCL}: &&\ \min_\theta \tilde L_h(\theta) &= \|\theta A^{-1} y - u_0\|^2_2 = (\theta-1)^2\|u_0\|_2^2\\
				\text{Penalty Method}: &&\ 
			\min_{\theta, u_h}\tilde L_h(\theta, u_h) &= \|u_h-u_0\|^2_2 + \lambda \|Au_h -\theta y\|_2^2
	\end{align*}
\begin{theorem}
	The condition number of $\mathbf{A}_\lambda$ is 
	\begin{equation*}
		\liminf_{\lambda\rightarrow \infty}\kappa(\mathbf{A}_\lambda)  =  \kappa(A)^2,\qquad \mathbf{A}_\lambda = \begin{bmatrix}
			I & 0\\
			\sqrt{\lambda}A & -\sqrt{\lambda}y
		\end{bmatrix}, \qquad 
		\mathbf{y} = \begin{bmatrix}
			u_0\\ 0
		\end{bmatrix}
	\end{equation*}
	and therefore, the condition number of the unconstrained optimization problem from the penalty method is equal to the square of the condition number of the PCL asymptotically. 
\end{theorem}
 	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Physics Constrained Learning for Stiff Problems}
	\begin{figure}[hbt]
		\centering
		\includegraphics[width=1.0\textwidth]{figures/pcl.png}
	\end{figure}
\end{frame}


\begin{frame}{Summary}
\begin{itemize}
\item Implicit and iterative operators are ubiquitous in numerical PDE solvers. These operators are insufficiently treated in deep learning software and frameworks.

\item Penalty methods suffer from slow convergence for stiff problems. 

\item First order physics constrained learning helps you calculate gradients of implicit/iterative operators efficiently. 

\item PCL leads to faster convergence and better accuracy compared to penalty methods.
\end{itemize}
\end{frame}

\section{Second Order Physics Constrained Learning}

\begin{frame}{Motivation}

\begin{itemize}
	\item First order methods and quasi-Newton methods are workhorse of physics informed machine learning 
	
	\begin{itemize}
		\item First order methods: stochastic gradient descent (SGD) and ADAM 
		%Slow convergence with long plateaus
		\item Quasi-Newton methods: BFGS and L-BFGS 
		% early termination 
	\end{itemize}

	\item Second order methods, such as trust region methods, are desirable for accelerating convergence and improving accuracy. 
	\begin{itemize}
		\item It requires us to calculate the curvature information (Hessians).
	\end{itemize}
\end{itemize}

\

\textbf{Goal}

\vspace{0.2cm} 

\begin{quote}
	Accelerate convergence and improve accuracy with Hessian information
\end{quote}

\end{frame}


\begin{frame}{Optimization Algorithms}
	
	
	\begin{figure}
		\centering
		\includegraphics[width=1.0\textwidth]{figures/thesis/optimization.png}
	\end{figure}
	
	
\end{frame}

\begin{frame}{Trust Region vs. Line Search}
	
	
	\begin{minipage}{0.6\textwidth}
		\textbf{Trust Region}
		
		\small
		
		\begin{itemize}
			\item Approximate $f(x_k + p)$ by a model quadratic function 
			$$m_k(p) = f_k + g_k^T p + \frac{1}{2}p^T B_k p$$
			$${\small f_k = f(x_k), g_k = \nabla f(x_k), B_k = \nabla^2 f(x_k)}$$
			\item Solve  the optimization problem within a trust region  $\|p\|\leq \Delta_k$
			\begin{equation*}
				p_k = \arg\min_{p} \; m_k(p) \quad	\text{s.t.} \; \|p\| \leq \Delta_k 
			\end{equation*}
			\vspace{-0.5cm}
			\item If decrease in $f(x_k + p_k)$ is sufficient, then update the state $x_{k+1} = x_k +  p_k$; otherwise, $x_{k+1} = x_k$ and improve $\Delta_k$.
		\end{itemize}
		
	\end{minipage}~
	\begin{minipage}{0.4\textwidth}
		\begin{figure}
			\centering
			\includegraphics[width=1.0\textwidth]{figures/thesis/tr_ls.PNG}
		\end{figure}
		
		\textbf{Line Search}
		
		\small
		\begin{itemize}
			\item Determine a descent direction $p_k$
			\item Determine a step size $\alpha_k$ that sufficiently reduces $f(x_k + \alpha_k p_k)$
			\item Update the state $x_{k+1} = x_k + \alpha_k p_k$
		\end{itemize}
	\end{minipage}
	
	
	
	
\end{frame}


\begin{frame}{Second-order Physics Constrained Learning}
	\begin{itemize}
\item Consider a composite function with a vector input $x$ and scalar output 
\begin{equation}\label{equ:t1}
	v = f(G(x))
\end{equation}
\item Define 
{\small
\begin{align*}
	f_{,k}(y) &= \frac{\partial f(y)}{\partial y_k}, \quad f_{,kl}(y) = \frac{\partial^2 f(y)}{\partial y_k \partial y_l} \\ 
	G_{k,l}(x) &=\frac{\partial G_k(x)}{\partial x_l},\quad G_{k, lr}(x) = \frac{\partial^2 G_k(x)}{\partial x_l\partial x_r}
\end{align*}
}
\item Differentiate \Cref{equ:t1} with respect to $x_i$
\begin{equation}\label{equ:t2}
\frac{\partial v}{\partial x_i} = f_{,k}G_{k,i}
\end{equation}
\item Differentiate \Cref{equ:t2} with respect to $x_j$
$$\boxed{\frac{\partial^2 v}{\partial x_i \partial x_j} = f_{,kr} G_{k,i} G_{r,j} + f_{,k} G_{k,ij}}$$
	\end{itemize}

\end{frame}


\begin{frame}{Second-order Physics Constrained Learning}


In the vector form,
$$\boxed{\nabla^2 v = (\nabla G)^T \nabla^2 f (\nabla G) + \nabla^2 (\bar G^T G)\qquad \bar G = \nabla f}$$

\begin{itemize}
\item Consider a function composed of a  sequence of computations
$$v = \Phi_m(\Phi_{m-1}(\cdots (\Phi_1(z))))$$
\end{itemize}


\begin{minipage}{0.7\textwidth}
	\small
\begin{algorithmic}[1]
	\State Initialize $H \gets 0$
	\For{$k=m-1, m-2, \ldots, 1$}
	\State Define $f:= \Phi_m (\Phi_{m-1} (\cdots (\Phi_{k+1}(\cdot))))$, $G:= \Phi_k$
	\State Calculate the gradient (Jacobian) $J \gets \nabla G$
	\State Extract $\bar G$ from the saved gradient back-propagation data. 
	\State Calculate $Z = \nabla^2(\bar G^T G)$ \label{algo:second-order-algo-update-line}
	\State Update $H \gets J^THJ + Z$
	\EndFor
\end{algorithmic}
\end{minipage}~
\begin{minipage}{0.3\textwidth}
\begin{figure}
	\centering
	\includegraphics[width=0.6\textwidth]{figures/thesis/computeH.png}
\end{figure}
\end{minipage}


\end{frame}


\begin{frame}{Numerical Benchmark}
\begin{itemize}
\item We consider the heat equation in $\Omega = [0,1]^2$
\begin{equation}\label{equ:second-order-ex2}
	\begin{aligned}
		\frac{\partial u}{\partial t} &= \nabla \cdot (\kappa(x, y) \nabla u))+  f(x, y) & x\in \Omega\\ 
		u(x,y,0) &= x(1-x)y^2(1-y)^2 & (x,y)\in \Omega\\
		u(x,y,t) &= 0 & (x,y)\in  \partial \Omega
	\end{aligned}
\end{equation}

\item The diffusivity coefficient $\kappa$ and exact solution $u$ are given by 

\begin{equation}
\begin{aligned}
	\kappa(x,y) &= 2x^2 - 1.05x^4 + x^6 +xy+y^2\\ 
	u(x,y,t) &= x(1-x)y^2(1-y)^2 e^{-t}
\end{aligned}
\end{equation}

\item We learn a DNN approximation to $\kappa$ using full-field observations of $u$

$$\kappa(x,y) \approx \text{NN}_\theta(x, y)$$
\end{itemize}
\end{frame}


\begin{frame}{Convergence}
	\begin{itemize}
		
		\item The optimization problem is given by 
		\begin{equation}
			\min_\theta\; L(\theta) = \sum_n\sum_{i,j} \left(\frac{u_{i,j}^{n+1} - u_{i,j}^n}{\Delta t} - F_{i,j}( u^{n+1}; \theta) -  f^{n+1}_{i,j}\right)^2 
		\end{equation}
		
		Here $F_{i,j}(u^{n+1}; \theta)$ is the 4-point finite difference approximation to the Laplacian $\nabla\cdot (\text{NN}_\theta \nabla u)$.
		
	
		\end{itemize}
	
		\begin{figure}[htbp]
		\centering
		\includegraphics[width=0.45\textwidth]{figures/thesis/losses2_dynamic.pdf}
	\end{figure}
	
\end{frame}

\begin{frame}{Effect of PDEs}
	\begin{itemize}
\item Consider the loss function excluding the effects of PDEs 
$$    l(\theta) = \sum_{i,j} (\text{NN}_\theta(x_{i,j}, y_{i,j}) - \kappa(x_{i,j}, y_{i,j}))^2 $$

\item Eigenvalue magnitudes of $\nabla^2 L(\theta)$ and $\nabla^2 l(\theta)$
	\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/thesis/pde_dnn.png}
\end{figure}
	\end{itemize}
\end{frame}

\begin{frame}{Effect of PDEs}
\begin{itemize}
\item Most of the eigenvalue directions at the local landscape of loss functions are ``flat'' $\Rightarrow$ ``effective degrees of freedom (DOFs)''. 

\item Physical constraints (PDEs) further cannibalize effective DOFs:

\

\begin{center}
		\begin{tabular}{@{}llll@{}}
		\toprule
		& BFGS & LBFGS & Trust Region \\ \midrule
		DNN-PDE     & \textbf{31}   & \textbf{22}    & \textbf{35}           \\
		DNN Only &  34   & 41    & 38           \\ \bottomrule
	\end{tabular}
\end{center}


\end{itemize}
\end{frame}

\begin{frame}{Effect of Widths and Depths}

\begin{itemize}
\item The ratio of zero eigenvalues \textbf{increases} as

\begin{itemize}
\item the number of hidden layers increase for a fixed number (20) of neurons per layer
\begin{center}
\begin{tabular}{@{}llll@{}}
	\toprule
	\# Hidden   Layers &  LBFGS & BFGS  & Trust Region \\ \midrule
	1                         & 76.54 & 72.84 & 77.78        \\
	2                        & 98.2  & 94.41 & 93.21        \\
	3                         & 98.7  & 98.15 & 96.09        \\ \bottomrule
\end{tabular}
\end{center}

\item the number of neurons per layer increases for a fixed number (3) of hidden layers
\begin{center}
	\begin{tabular}{@{}lllll@{}}
		\toprule
		\# Neurons per Layer & LBFGS & BFGS  & Trust Region \\ \midrule
		5                         & 93.83 & 85.19 & 69.14        \\
		10                         & 97.7  & 83.52 & 89.66        \\
		20                        & 96.2  & 97.39 & 96.42        \\ \bottomrule
	\end{tabular}
\end{center}
\end{itemize}
\end{itemize}

\end{frame}


\begin{frame}{Effect of Widths and Depths}
\begin{itemize}
\item Implications for overparametrization: \textbf{the minimizer lies on a relatively higher dimensional manifold of the parameter space}.
\end{itemize}

	\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/thesis/min.png}
\end{figure}
\end{frame}

\begin{frame}{Summary}
	\begin{itemize}
\item Trust region methods converge significantly faster compared to first order/quasi second order methods by leveraging Hessian information. 

\item Second order physics constrained learning helps you calculate Hessian matrices efficiently. 

\item The local minimum of DNNs have small effective degrees of freedom compared to DNN sizes. 
	\end{itemize}
\end{frame}

\section{Generative Neural Networks for Stochastic Inverse Problems}

\begin{frame}{Motivation}
		\begin{equation*}
		\min_{\textcolor{red}{f}} L_h(u_h) \quad \mathrm{s.t.}\; F_h(\textcolor{red}{f}, u_h) = 0
	\end{equation*}
	\begin{itemize}
\item What if $f$ is a random variable?
\begin{itemize}
	\item uncertainty estimation
\end{itemize}
\item What if $F_h$ is a stochastic model?
\begin{itemize}
	\item stochastic differential equations (SDE)
\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Methodologies}
		\begin{figure}[htbp]
		\centering
		\includegraphics[width=1.0\textwidth]{figures/thesis/dist.png}
	\end{figure}
\end{frame}

\begin{frame}{Modeling Stochasticity using Deep Neural Networks}


\begin{itemize}
\item We consider a map $F$
$$F: (w, \theta) \mapsto u(\cdot, \cdot)$$
\begin{itemize}
\item $w$ is sampled from a \textbf{know} stochastic process (stochasticity intrinsic to the model).
\item $\theta$ is a random variable of interest. 
\item $u(x,t)$ is the output of the mapping, which depends on the location $x$ and time $t$. $u$ is also a random variable. 
 \end{itemize}
\item Examples:

\begin{itemize}
\item CIR process (a short-term interest rate model)
$$dr_t = \kappa(\tau-r_t)dt + \sqrt{r_t}\sigma dW_t$$
Here $\theta = (\kappa, \tau, \sigma)$, $w = W_t$, and $u = r_t$.
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Adversarial Inverse Modeling (AIM)}
	\begin{itemize}
\item Approximate the unknown distribution $\theta$ with a DNN $G_\eta$ (generator);
\item A discriminator $D_\xi$ tries to distinguish between generated and observed samples.
	\end{itemize}
	\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/thesis/ana.pdf}
\end{figure}
\end{frame}

\begin{frame}{Adversarial Inverse Modeling}
	\begin{itemize}
\item Find the \textbf{Nash equilibrium} by solving a min-max problem 
$$\min_\eta \max_\xi\; V(D_\xi, G_\eta)$$
Here $V$ is the reward to the discriminator $D$ for distinguishing  generated and observed samples.
\item Inspired by generative adversarial nets (GAN): iteratively minimizing discriminator and generator loss functions
\begin{itemize}
\item Example: Kullback-Leibler (KL) GAN
\begin{equation*}
	\begin{aligned}
		L^G(\{\hat u_i\}; {\color{red}\eta}) =&  \frac{1}{n}\sum_{i=1}^n \log\frac{ 1-D_{\xi}(\hat  u_i({\color{red}\eta}))}{D_{\xi}(\hat  u_i({\color{red}\eta}))} \\
		L^D(\{ u_i\}, \{\hat u_i\}; {\color{red}\xi}) =& -\frac{1}{n}\sum_{i=1}^n \left( \log D_{\color{red}\xi}(\hat  u_i) + \log(1-D_{\color{red}\xi}( u_i)) \right)
	\end{aligned} 
\end{equation*}
\end{itemize}  
	\end{itemize}

\end{frame}


\begin{frame}{Numerical Benchmarks}

\begin{itemize}
\item We consider a Poisson equation 
$$\begin{cases}
	-\nabla \cdot (a(x)\nabla u(x)) = 1 & x\in(0,1)\\
	u(0) = u(1) = 0 & \mbox{otherwise}
\end{cases}$$
$$a(x) = 1-0.9\exp\left( -\frac{(x-{\color{red}\mu})^2}{2{\sigma}^2} \right)$$
\end{itemize}
	\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{figures/thesis/aim.png}
\end{figure}
\end{frame}

\begin{frame}{Optimal Transport}
	\begin{itemize}
\item Solve the transport matrix from a linear programming problem 
\begin{equation}
	\begin{aligned}
		\min_{p_{ij}} &\; W(\mathbf{p}; \mathbf{x}, \by) = \sum_{i=1}^n \sum_{j=1}^m p_{ij} \underline{c}_{ij} \\
		\mathrm{s.t.}\;\; & \sum_{j=1}^m p_{ij} = \frac{1}{n},\;\; \sum_{i=1}^n p_{ij} = \frac{1}{m},\;\; 0\leq p_{ij}\leq 1
	\end{aligned}
\end{equation}

\item Discrete Wasserstein distance between two sets of samples:

$$	D(\mathbf{x}, \by) = W(\mathbf{p}^*; \mathbf{x}, \by) = \hspace{-4pt} \sum_{1\leq i\leq n, 1\leq j\leq m} \hspace{-4pt} p^*_{ij} \|x_i-y_j\|_1$$


	\end{itemize}
\end{frame}


\begin{frame}{AD for Discrete Wasserstein Distance}
\begin{theorem}
	Assume that $\mathbf{p}^*([\uc_{ij}])$ is the optimal solution to the linear programming problem given the cost matrix $[\uc_{ij}]$, then we have 
	\begin{equation*}
		\frac{\partial W(\mathbf{p}^*([\uc_{ij}]))}{\partial \uc_{ij}} = p^*_{ij}
	\end{equation*}
\end{theorem}
\end{frame}


\begin{frame}{PhysGNN: Training Generative Neural Networks with Discrete Wasserstein Distance}
	\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{figures/thesis/ill1}
\end{figure}
\end{frame}

\begin{frame}{Numerical Benchmarks}
	
	\begin{itemize}
		\item We consider a 2D Poisson's equation
\begin{equation}
	\begin{aligned}
		\nabla \cdot (\kappa\nabla u) &= 2\pi^2\sin(\pi x) \sin(\pi y) & (x,y)\in (0,1)^2\\
		u(x,y) &= 0 & (x,y)\in \partial (0,1)^2 
	\end{aligned}
\end{equation}
$$\kappa = |v|, \quad v \sim \mathcal{N}(1.0, 0.3^2)$$
\item Observation:  $u(0.8,0.8)$
\item $\sim$ 20,000 PDE solves for both MCMC and PhysGNN:
	\end{itemize}


\begin{figure}[hbt]
	\centering
    \includegraphics[width=0.8\textwidth]{figures/thesis/compare_mcmc_data.pdf}
\end{figure}

\end{frame}

\begin{frame}{Summary}
	\begin{itemize}
		\item Generative neural networks are used to approximate unknown distributions in a stochastic inverse problem. 
		\item Training generative neural networks
		\begin{itemize}
			\item Adversarial inverse modeling (AIM): solving a min-max optimization problem involving  generator and discriminator nets
			\item Physics Generative Neural Network (PhysGNN): minimizing a discrete Wasserstein distance
		\end{itemize}
	\end{itemize}
	
\end{frame}

\section{Conclusion}


\begin{frame}
	\frametitle{Applications}
	

\begin{figure}[hbt]
	\centering
	\includegraphics[width=0.9\textwidth]{figures/thesis/pub}
\end{figure}
\end{frame}

\begin{frame}
	\frametitle{A General Approach to Inverse Modeling}
	\begin{figure}[hbt]
		\includegraphics[width=1.0\textwidth]{figures/summary.png}
	\end{figure}
\end{frame}

\begin{frame}
PLACEHOLDER
\end{frame}


%}
%\usebackgroundtemplate{}
%----------------------------------------------------------------------------------------
%    PRESENTATION SLIDES
%----------------------------------------------------------------------------------------

%------------------------------------------------



\end{document} 